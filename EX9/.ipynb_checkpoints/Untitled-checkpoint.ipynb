{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Training an image classifier on CIFAR10\n",
    "\n",
    "'''\n",
    "\n",
    "# imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# allow the code to run on a GPU if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "'''\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "'''\n",
    "########################################################################\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1].\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar-10-batches-py', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img, label):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.title(label)\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "2. Define a ResNet\n",
    "'''\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO write the forward pass for the residual block as shown in figure 2\n",
    "        \n",
    "        # pass the input x through the first convolutional layer, a first batch-\n",
    "        # normalization and a ReLU activation        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        # pass the output from this through the second convolutional layer and \n",
    "        # a second batch-normalization         \n",
    "        out = self.bn2(self.conv2(out))        \n",
    "        # add the input x to this after passing it through the shortcut\n",
    "        out += self.shortcut(x)\n",
    "        # pass the result through another ReLU activation\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3,4,6,3])\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3,4,6,3])\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3,4,23,3])\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3,8,36,3])\n",
    "\n",
    "net = ResNet18()\n",
    "\n",
    "net.to(device)\n",
    "    \n",
    "'''\n",
    "3. Define a loss function\n",
    "'''\n",
    "#TODO Use a Cross-Entropy Loss and Adam as optimizer\n",
    "criterion =  nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0003)\n",
    "\n",
    "\n",
    "'''\n",
    "4. Train the network on the training data\n",
    "'''\n",
    "# Loop over the data iterator, and feed the inputs to the\n",
    "# network and optimize.\n",
    "\n",
    "n_epochs = 10\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "    epoch_loss = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # TODO get the inputs\n",
    "        #print(data[1][0].item())\n",
    "        #print(data[0])\n",
    "        #print(data[1])\n",
    "        #import pdb; pdb.set_trace()\n",
    "        #print(len(data))\n",
    "        #print(data[0].size())\n",
    "        #print(data[1])\n",
    "        input, target = data[0].to(device), data[1].to(device)\n",
    "        # TODO zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # TODO forward + backward + optimize\n",
    "        loss = criterion(net.forward(input), target)\n",
    "        epoch_loss += loss.item()\n",
    "        loss_history.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        # TODO plot the loss evolution\n",
    "\n",
    "loss_history = np.array(loss_history)\n",
    "loss_history.tofile('/home/mlcvss18_7/PaulHiltResNet/loss_history.dat')\n",
    "        \n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "'''\n",
    "5. Test the network on the test data\n",
    "'''\n",
    "# TODO Evaluate the performance of the network by predicting the class label that the neural network\n",
    "# outputs, and checking it against the ground-truth. If the prediction is\n",
    "# correct, add the sample to the list of correct predictions.\n",
    "# The outputs are energies for the 10 classes.\n",
    "# Higher the energy for a class, the more the network\n",
    "# thinks that the image is of the particular class.\n",
    "# So, you get the predicted class as the index of the highest energy.\n",
    "# Compute the overall accuracy and the accuracy for each class.\n",
    "passed_img = []\n",
    "passed_lbl = []\n",
    "failed_img = []\n",
    "failed_lbl = []\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    #input, target = data[0].to(device), data[1].to(device)\n",
    "    #out = net.forward(input)\n",
    "    print(data[1][k].size())\n",
    "    import pdb; pdb.set_trace()\n",
    "    for k in range(4):\n",
    "        if(data[1][k].item() == torch.argmax(out[k]).item()):\n",
    "            print(\"\\n\\nPASSED, pic is a:\")\n",
    "            print(classes[data[1][k].item()])\n",
    "            passed_img.append(data[0][k].numpy().tolist())\n",
    "            passed_lbl.append(data[1][k].numpy().tolist())\n",
    "        else:\n",
    "            print(\"\\n\\nFAILED\")\n",
    "            print(torch.argmax(out[k]).item())\n",
    "            failed_img.append(data[0][k].numpy().tolist())\n",
    "            failed_lbl.append(data[1][k].numpy().tolist())\n",
    "    \n",
    "#for i in range(len(passed_set)):\n",
    "#    imshow(passed_set[i], passed_lbl[i])\n",
    "#for i in range(len(passed_set)):\n",
    "#    imshow(failed_set[i], failed_lbl[i])\n",
    "    \n",
    "# Save failed and passed sets as well as the NN\n",
    "torch.save(net.state_dict(), '/home/mlcvss18_7/PaulHiltResNet/NN')\n",
    "\n",
    "\n",
    "passed_img = np.array(passed_img)\n",
    "passed_lbl = np.array(passed_lbl)\n",
    "failed_img = np.array(failed_img)\n",
    "failed_lbl = np.array(failed_lbl)\n",
    "\n",
    "passed_img.tofile('/home/mlcvss18_7/PaulHiltResNet/passed_img.dat')\n",
    "passed_lbl.tofile('/home/mlcvss18_7/PaulHiltResNet/passed_lbl.dat')\n",
    "failed_img.tofile('/home/mlcvss18_7/PaulHiltResNet/failed_img.dat')\n",
    "failed_lbl.tofile('/home/mlcvss18_7/PaulHiltResNet/failed_lbl.dat')\n",
    "\n",
    "#the_model = ResNet18()\n",
    "#the_model.load_state_dict(torch.load('./NN'))\n",
    "\n",
    "#passed_img = np.fromfile('./passed_img.dat', dtype=int)\n",
    "\n",
    "print('FINISHED!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), '/home/mlcvss18_7/PaulHiltResNet/NN')\n",
    "\n",
    "passed_img = np.array(passed_img)\n",
    "passed_lbl = np.array(passed_lbl)\n",
    "failed_img = np.array(failed_img)\n",
    "failed_lbl = np.array(failed_lbl)\n",
    "\n",
    "passed_img.tofile('/home/mlcvss18_7/PaulHiltResNet/passed_img.dat')\n",
    "passed_lbl.tofile('/home/mlcvss18_7/PaulHiltResNet/passed_lbl.dat')\n",
    "failed_img.tofile('/home/mlcvss18_7/PaulHiltResNet/failed_img.dat')\n",
    "failed_lbl.tofile('/home/mlcvss18_7/PaulHiltResNet/failed_lbl.dat')\n",
    "\n",
    "the_model = ResNet18()\n",
    "the_model.load_state_dict(torch.load('./NN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
